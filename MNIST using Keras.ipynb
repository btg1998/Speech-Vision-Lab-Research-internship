{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Basic Idea is to create a CNN using keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "628e19f8-fdd6-4de6-a82b-7c96f33f6ce8",
    "_uuid": "3a8bcda50bdd505510ddf99f96f5efda6ade53af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "dff0d53c63f50ec8a8de7f0b299d3c5d73e65e8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Required Sklearn and Keras Functions\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9b231890119bae178a166301d2ddaea6f15dd3d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the Random Seed\n",
    "seed = 2\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "939f0f6c346051c58688bbb7aa133b48e2f5b22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "# Load the training Data\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "23e52ba3b2a66bfca6ee076c9b88dd2a3298062f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 4684, 7: 4401, 3: 4351, 9: 4188, 2: 4177, 6: 4137, 0: 4132, 4: 4072, 8: 4063, 5: 3795}\n"
     ]
    }
   ],
   "source": [
    "# Creating X and y to fit on the model\n",
    "y = train[\"label\"]\n",
    "X = train.drop(\"label\", axis = 1) \n",
    "# Get a look at the Images\n",
    "print(y.value_counts().to_dict())\n",
    "y = to_categorical(y, num_classes = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e6759aafda942ca6baf12fe97dc12eedb52a52f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing the Data\n",
    "X = X / 255.0\n",
    "# Reshaping the Grayscale Images to be fit into the CNN\n",
    "X = X.values.reshape(-1,28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "20fda50c5fde60e0299b00d3a5faf5268a02ecc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 28, 28, 1) (4200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into Training and Validation Sets\n",
    "train_index, valid_index = ShuffleSplit(n_splits=1, train_size=0.9, test_size=None, random_state=seed).split(X).__next__()\n",
    "train_x = X[train_index]\n",
    "train_y = y[train_index]\n",
    "valid_x = X[valid_index]\n",
    "valid_y = y[valid_index]\n",
    "print(train_x.shape, valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "f2e86501345ac2ef8a2b5aaaaca4fee58e563419",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the Model\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "e2422f18cc707ad4c614d30bfc3b3f26708f7d6c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First Block with 2 Convultional layers, 1 maxpool layer and with a dropout \n",
    "# Valid Padding\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Valid', activation ='relu', input_shape = (28,28,1)))\n",
    "# Same padding\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "a5fddbd69c4af7d8a00ecd3e3c5089d0e73ce1f8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second block with 2 Convolutional layers, 1 maxpool layer and with a droput\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ffcf54e6c1bde997e246393c59337f19547d838b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third and final Block with a flatten layer and softmax output layer with a dropout too \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "15716225f8453093e0cd18e2a72dd94673e6142e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using an Adam Optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
    "# To Reduce Learning Rate once Plateau is reached accuracy wise\n",
    "annealer = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "62b32398057f4d9feceec7c7761def166d247b31",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting Epoch and batch Size\n",
    "epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1db66581a05e44aaf697e9568cc54c92920494b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre Processing the Data to be fit into the model \n",
    "datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False, zca_whitening=False, rotation_range=10, zoom_range = 0.1, width_shift_range=0.1,\n",
    "        height_shift_range=0.1, horizontal_flip=False, vertical_flip=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2ddf717b21c78729f097892b095c0ff4666f7702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 124s - loss: 0.4818 - acc: 0.8402 - val_loss: 0.0648 - val_acc: 0.9700\n",
      "Epoch 2/20\n",
      " - 123s - loss: 0.1250 - acc: 0.9647 - val_loss: 0.0405 - val_acc: 0.9900\n",
      "Epoch 3/20\n",
      " - 126s - loss: 0.0936 - acc: 0.9731 - val_loss: 0.0306 - val_acc: 0.9917\n",
      "Epoch 4/20\n",
      " - 122s - loss: 0.0788 - acc: 0.9775 - val_loss: 0.0320 - val_acc: 0.9917\n",
      "Epoch 5/20\n",
      " - 123s - loss: 0.0711 - acc: 0.9803 - val_loss: 0.0332 - val_acc: 0.9900\n",
      "Epoch 6/20\n",
      " - 124s - loss: 0.0652 - acc: 0.9814 - val_loss: 0.0312 - val_acc: 0.9950\n",
      "Epoch 7/20\n",
      " - 119s - loss: 0.0609 - acc: 0.9833 - val_loss: 0.0370 - val_acc: 0.9917\n",
      "Epoch 8/20\n",
      " - 121s - loss: 0.0587 - acc: 0.9839 - val_loss: 0.0206 - val_acc: 0.9950\n",
      "Epoch 9/20\n",
      " - 122s - loss: 0.0536 - acc: 0.9844 - val_loss: 0.0238 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/20\n",
      " - 122s - loss: 0.0396 - acc: 0.9886 - val_loss: 0.0106 - val_acc: 0.9967\n",
      "Epoch 11/20\n",
      " - 121s - loss: 0.0336 - acc: 0.9906 - val_loss: 0.0099 - val_acc: 0.9967\n",
      "Epoch 12/20\n",
      " - 125s - loss: 0.0316 - acc: 0.9914 - val_loss: 0.0129 - val_acc: 0.9983\n",
      "Epoch 13/20\n",
      " - 126s - loss: 0.0311 - acc: 0.9910 - val_loss: 0.0170 - val_acc: 0.9950\n",
      "Epoch 14/20\n",
      " - 127s - loss: 0.0326 - acc: 0.9906 - val_loss: 0.0151 - val_acc: 0.9967\n",
      "Epoch 15/20\n",
      " - 125s - loss: 0.0304 - acc: 0.9909 - val_loss: 0.0134 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 16/20\n",
      " - 123s - loss: 0.0256 - acc: 0.9927 - val_loss: 0.0112 - val_acc: 0.9983\n",
      "Epoch 17/20\n",
      " - 124s - loss: 0.0255 - acc: 0.9925 - val_loss: 0.0113 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/20\n",
      " - 124s - loss: 0.0190 - acc: 0.9945 - val_loss: 0.0147 - val_acc: 0.9950\n",
      "Epoch 19/20\n",
      " - 132s - loss: 0.0192 - acc: 0.9941 - val_loss: 0.0120 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/20\n",
      " - 125s - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0186 - val_acc: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4d1a2f320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting on the Model\n",
    "model.fit_generator(datagen.flow(train_x,train_y,batch_size=batch_size), epochs=epochs, validation_data=(valid_x[:600,:],valid_y[:600,:]),\n",
    "                              verbose = 2, steps_per_epoch=train_x.shape[0]//batch_size, callbacks=[annealer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "dcad17e379e8038d771421f3ee54b3ccaaabdb83",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "# On Training Set\n",
    "tr_ps =  model.predict(train_x)\n",
    "tr_p = np.max(tr_ps, axis=1)\n",
    "tr_pl = np.argmax(tr_ps, axis=1)\n",
    "# On Validation Set \n",
    "vl_ps = model.predict(valid_x)\n",
    "vl_p = np.max(vl_ps, axis=1)\n",
    "vl_pl = np.argmax(vl_ps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "48e50f4f81b07ab0c2e6194ddc86378c541ef6fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(tr_y_err.shape[0]):\\n    plt.imsave(fname='train_err_%d_%d_%d.csv'%(tr_y_err[i], tr_pl_err[i], i), arr=tr_x_err[i].reshape(28,28),format='png')\\nfor i in range(vl_y_err.shape[0]):\\n    plt.imsave(fname='valid_err_%d_%d_%d.csv'%(vl_y_err[i], vl_pl_err[i], i), arr=vl_x_err[i].reshape(28,28),format='png')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrongly Classified Images\n",
    "# On Training\n",
    "tr_y = np.argmax(train_y, axis=1)\n",
    "tr_x_err = train_x[tr_y != tr_pl]\n",
    "tr_y_err = tr_y[tr_y != tr_pl]\n",
    "tr_pl_err = tr_pl[tr_y != tr_pl]\n",
    "# On Validation\n",
    "vl_y = np.argmax(valid_y, axis=1)\n",
    "vl_x_err = valid_x[vl_y != vl_pl]\n",
    "vl_y_err = vl_y[vl_y != vl_pl]\n",
    "vl_pl_err = vl_pl[vl_y != vl_pl]\n",
    "# To See the wrongly classified images for Feedback Purposes\n",
    "'''\n",
    "for i in range(tr_y_err.shape[0]):\n",
    "    plt.imsave(fname='train_err_%d_%d_%d.csv'%(tr_y_err[i], tr_pl_err[i], i), arr=tr_x_err[i].reshape(28,28),format='png')\n",
    "for i in range(vl_y_err.shape[0]):\n",
    "    plt.imsave(fname='valid_err_%d_%d_%d.csv'%(vl_y_err[i], vl_pl_err[i], i), arr=vl_x_err[i].reshape(28,28),format='png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "57436fc77a7b3640a0646f95d5c7ec6ed67d9a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model scores:\n",
      "model valid loss: 0.0202, valid accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "print('Base model scores:')\n",
    "valid_loss, valid_acc = model.evaluate(valid_x, valid_y, verbose=0)\n",
    "print(\"model valid loss: {0:.4f}, valid accuracy: {1:.4f}\".format(valid_loss, valid_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "4d12de7f45fd90329a38dbee829496c4c5d8bbd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[410   0   0   0   0   0   1   0   0   0]\n",
      " [  0 482   0   0   0   0   0   2   1   0]\n",
      " [  0   0 402   1   0   0   0   0   0   0]\n",
      " [  0   0   0 417   0   0   0   0   1   0]\n",
      " [  0   0   0   0 458   0   1   0   0   2]\n",
      " [  0   0   0   2   0 367   1   0   2   0]\n",
      " [  0   0   0   0   1   0 410   0   2   0]\n",
      " [  0   0   0   0   0   0   0 445   0   1]\n",
      " [  0   0   0   0   0   0   0   0 381   1]\n",
      " [  0   0   0   0   1   0   0   1   0 407]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix on the validation set\n",
    "valid_p = np.argmax(model.predict(valid_x), axis=1)\n",
    "target = np.argmax(valid_y, axis=1)\n",
    "cm = confusion_matrix(target, valid_p)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "04e0e8e3e3944cc8eebe5cc67ced01dbb6275596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Now on to the predictions on the Test Set\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "b78e0a6f7d05484e162549905d8a59e17dbc603d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing and Re-Shaping the Test Data to be fit into the CNN we made\n",
    "test = test / 255.0\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "# Predictions on the Test Set\n",
    "p = np.argmax(model.predict(test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "691d91e9c070c7da604a6397f544c4bf48426173",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the Submission File\n",
    "submission = pd.DataFrame(pd.Series(range(1, p.shape[0]+1), name='ImageId'))\n",
    "submission['Label'] = p\n",
    "submission.to_csv(\"CNN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eaa23673d678f8b0e7276c1cfac435d642ee7ff3",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
