{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Stacked Auto Encoder in PyTorch on the CIFAR 10 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Required Header Files\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Loading the Training Data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True,\n",
    "                     transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=True)\n",
    "# Using Batch Size of 128 since it performed well in previous case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Testing Data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=False)\n",
    "# Using Batch Size of 128 since it performed well in previous case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Stacked Auto Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_size=256 # Tried sizes of 32/64/128/256\n",
    "hidden_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAE, self).__init__()\n",
    "\n",
    "        # Defining the Architecture of the Stacked Auto Encoder \n",
    "            \n",
    "        # Encoder Part\n",
    "        self.conv1 = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 32, intermediate_size)\n",
    "\n",
    "        # Bottle-Neck Part with Latent Space\n",
    "        #self.fc21 = nn.Linear(intermediate_size, hidden_size)\n",
    "        #self.fc22 = nn.Linear(intermediate_size, hidden_size)\n",
    "\n",
    "        # Decoder Part\n",
    "        #self.fc3 = nn.Linear(hidden_size, intermediate_size)\n",
    "        self.fc4 = nn.Linear(intermediate_size, 8192)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv5 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(out))\n",
    "        #return self.fc21(h1), self.fc22(h1)\n",
    "        return h1\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        #h3 = self.relu(self.fc3(z))\n",
    "        #out = self.relu(self.fc4(h3))\n",
    "        out = self.relu(self.fc4(z))\n",
    "        out = out.view(out.size(0), 32, 16, 16)\n",
    "        out = self.relu(self.deconv1(out))\n",
    "        out = self.relu(self.deconv2(out))\n",
    "        out = self.relu(self.deconv3(out))\n",
    "        out = self.sigmoid(self.conv5(out))\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        #mu, logvar = self.encode(x)\n",
    "        z=self.encode(x)\n",
    "        #z = self.reparameterize(mu, logvar)\n",
    "        #return self.decode(z), mu, logvar\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a model based on the above architecture\n",
    "model = SAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAE(\n",
       "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=8192, bias=True)\n",
       "  (deconv1): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (deconv2): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (deconv3): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv5): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving model to cuda to train on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an OPtimizer\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Loss Function with latent space\n",
    "# There are 2 different losses:\n",
    "# Reconstruction + Divergence\n",
    "'''\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    R = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "    D = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return R + D\n",
    "'''\n",
    "# Below is the loss function for the without latent space part\n",
    "def loss_function(recon_x,x):\n",
    "    criterion = nn.BCELoss()\n",
    "    return criterion(recon_x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training the model many times\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        #recon_batch, mu, logvar = model(data)\n",
    "        recon_batch = model(data)\n",
    "        #loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss = loss_function(recon_batch, data)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        #recon_batch, mu, logvar = model(data)\n",
    "        recon_batch = model(data)\n",
    "        #test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "        test_loss += loss_function(recon_batch, data).data[0]\n",
    "        if epoch == 9 and i == 0:\n",
    "            n = min(data.size(0), 8)\n",
    "            comparison = torch.cat([data[:n],\n",
    "                                   recon_batch[:n]])\n",
    "            save_image(comparison.data.cpu(),\n",
    "                       'snapshots/conv_sae/reconstruction_1.3_'+ str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 0.005418\n",
      "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 0.005212\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 0.004991\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 0.004768\n",
      "====> Epoch: 0 Average loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.0048\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.004741\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.004658\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.004682\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.004744\n",
      "====> Epoch: 1 Average loss: 0.0047\n",
      "====> Test set loss: 0.0047\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.004649\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.004682\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.004666\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.004624\n",
      "====> Epoch: 2 Average loss: 0.0047\n",
      "====> Test set loss: 0.0047\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.004630\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.004546\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.004596\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.004558\n",
      "====> Epoch: 3 Average loss: 0.0046\n",
      "====> Test set loss: 0.0046\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.004558\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.004557\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.004585\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.004563\n",
      "====> Epoch: 4 Average loss: 0.0046\n",
      "====> Test set loss: 0.0046\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.004584\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.004604\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.004510\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.004591\n",
      "====> Epoch: 5 Average loss: 0.0046\n",
      "====> Test set loss: 0.0046\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.004533\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.004575\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.004498\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.004521\n",
      "====> Epoch: 6 Average loss: 0.0045\n",
      "====> Test set loss: 0.0046\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.004499\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.004463\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.004482\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.004452\n",
      "====> Epoch: 7 Average loss: 0.0045\n",
      "====> Test set loss: 0.0046\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.004598\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.004542\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.004479\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.004604\n",
      "====> Epoch: 8 Average loss: 0.0045\n",
      "====> Test set loss: 0.0046\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.004587\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.004521\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.004513\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.004524\n",
      "====> Epoch: 9 Average loss: 0.0045\n",
      "====> Test set loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    '''\n",
    "    if epoch == 9:\n",
    "        sample = Variable(torch.randn(64, hidden_size))\n",
    "        sample = sample.cuda()\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.data.view(64, 3, 32, 32),\n",
    "                   'snapshots/sample_1_' + str(epoch) + '.png')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
